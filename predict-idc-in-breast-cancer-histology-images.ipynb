{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"*Step 1: Importing the necessary Modules*","metadata":{"_cell_guid":"eb849bd9-7894-4fd3-b55d-4d0a77c9161c","_uuid":"debe60106fe79d3b2316308fd11f3d2399255c61"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nfrom glob import glob\nimport itertools\nimport fnmatch\nimport random\nimport matplotlib.pylab as plt\nimport seaborn as sns\nimport cv2\nfrom scipy.misc import imresize, imread\nimport sklearn\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold, learning_curve, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, make_scorer, accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nimport keras\n\nfrom keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom keras.models import Sequential, model_from_json\nfrom keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta\nfrom keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPool2D, MaxPooling2D\n%matplotlib inline","metadata":{"_cell_guid":"bb9fe3ef-104a-4a98-9f87-b65906acf50f","_kg_hide-input":true,"_uuid":"5a9827f8d703a8741175d1e7df3121632715bdd8","execution":{"iopub.status.busy":"2022-10-11T05:13:52.629912Z","iopub.execute_input":"2022-10-11T05:13:52.630178Z","iopub.status.idle":"2022-10-11T05:13:54.149572Z","shell.execute_reply.started":"2022-10-11T05:13:52.630123Z","shell.execute_reply":"2022-10-11T05:13:54.061012Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"Using TensorFlow backend.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0m_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/imp.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(name, file, filename, details)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[0;34m(name, path, file)\u001b[0m\n\u001b[1;32m    342\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: libcuda.so.1: cannot open shared object file: No such file or directory","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-dcfc01d9fc93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimresize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_curve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/Keras-2.1.4-py3.6.egg/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/Keras-2.1.4-py3.6.egg/keras/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Globally-importable utils.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/Keras-2.1.4-py3.6.egg/keras/utils/conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/Keras-2.1.4-py3.6.egg/keras/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown backend: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_BACKEND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/Keras-2.1.4-py3.6.egg/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_array_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Protocol buffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[0;32m---> 74\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/opt/conda/lib/python3.6/imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/opt/conda/lib/python3.6/imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: libcuda.so.1: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."],"ename":"ImportError","evalue":"Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/opt/conda/lib/python3.6/imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/opt/conda/lib/python3.6/imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: libcuda.so.1: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.","output_type":"error"}]},{"cell_type":"markdown","source":"*Step 2: Data Exploration*","metadata":{"_cell_guid":"4c6bd2df-2a43-4604-b407-ba81c8c3939b","_uuid":"540f3c39324580297bcff94b4c4cfc0c5bb45b5f"}},{"cell_type":"code","source":"imagePatches = glob('/kaggle/input/IDC_regular_ps50_idx5/**/*.png', recursive=True)\nfor filename in imagePatches[0:10]:\n    print(filename)","metadata":{"_cell_guid":"765908c1-86cc-41df-8479-a39174231237","_uuid":"1978266e1e2fe5d6eb9bdc17deb0d309441065a2","execution":{"iopub.status.busy":"2022-10-11T05:13:54.061973Z","iopub.status.idle":"2022-10-11T05:13:54.062299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_name = \"/kaggle/input/IDC_regular_ps50_idx5/9135/1/9135_idx5_x1701_y1851_class1.png\" #Image\ndef plotImage(image_location):\n    image = cv2.imread(image_name)\n    image = cv2.resize(image, (50,50))\n    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)); plt.axis('off')\n    return\nplotImage(image_name)","metadata":{"_cell_guid":"0fd6c75a-b439-455c-ba85-24aa9d83da5b","_uuid":"1d105b2c6fff7ddfd3120215ea7f77723e360179","execution":{"iopub.status.busy":"2022-10-11T05:13:54.063152Z","iopub.status.idle":"2022-10-11T05:13:54.063776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot Images\nbunchOfImages = imagePatches\ni_ = 0\nplt.rcParams['figure.figsize'] = (10.0, 10.0)\nplt.subplots_adjust(wspace=0, hspace=0)\nfor l in bunchOfImages[:25]:\n    im = cv2.imread(l)\n    im = cv2.resize(im, (50, 50)) \n    plt.subplot(5, 5, i_+1) #.set_title(l)\n    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n    i_ += 1","metadata":{"_cell_guid":"cfc417f1-c12a-42df-b264-c4e7e6e79da8","_uuid":"f9d9578ed454625dbe08a3185865cc3ae556b993","execution":{"iopub.status.busy":"2022-10-11T05:13:54.064507Z","iopub.status.idle":"2022-10-11T05:13:54.065301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def randomImages(a):\n    r = random.sample(a, 4)\n    plt.figure(figsize=(16,16))\n    plt.subplot(131)\n    plt.imshow(cv2.imread(r[0]))\n    plt.subplot(132)\n    plt.imshow(cv2.imread(r[1]))\n    plt.subplot(133)\n    plt.imshow(cv2.imread(r[2])); \nrandomImages(imagePatches)","metadata":{"_cell_guid":"f010fda5-40f0-47ce-89c0-40d21a754f59","_uuid":"10cc771383f08fd404419bccaa00ed9ad99cd0e2","execution":{"iopub.status.busy":"2022-10-11T05:13:54.066088Z","iopub.status.idle":"2022-10-11T05:13:54.066689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Step 3: Preprocessing the Data*","metadata":{"_cell_guid":"5f695df0-da48-4cc5-93a0-dcb7a82d21a3","_uuid":"c88fc872e6af3918192df09635e88904145761a2"}},{"cell_type":"code","source":"patternZero = '*class0.png'\npatternOne = '*class1.png'\nclassZero = fnmatch.filter(imagePatches, patternZero)\nclassOne = fnmatch.filter(imagePatches, patternOne)\nprint(\"IDC(-)\\n\\n\",classZero[0:5],'\\n')\nprint(\"IDC(+)\\n\\n\",classOne[0:5])","metadata":{"_cell_guid":"939bc134-6122-4d4d-aa6c-89a47318896d","_uuid":"aae6a2ec2ab20bd94422e29b147a45a880fb480a","execution":{"iopub.status.busy":"2022-10-11T05:13:54.067568Z","iopub.status.idle":"2022-10-11T05:13:54.068087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def proc_images(lowerIndex,upperIndex):\n    \"\"\"\n    Returns two arrays: \n        x is an array of resized images\n        y is an array of labels\n    \"\"\" \n    x = []\n    y = []\n    WIDTH = 50\n    HEIGHT = 50\n    for img in imagePatches[lowerIndex:upperIndex]:\n        full_size_image = cv2.imread(img)\n        x.append(cv2.resize(full_size_image, (WIDTH,HEIGHT), interpolation=cv2.INTER_CUBIC))\n        if img in classZero:\n            y.append(0)\n        elif img in classOne:\n            y.append(1)\n        else:\n            return\n    return x,y","metadata":{"_cell_guid":"f62e9e56-6564-4376-845f-284f624fa932","_uuid":"69640054f59133ebe8dfa06612f3c14383916e90","execution":{"iopub.status.busy":"2022-10-11T05:13:54.069167Z","iopub.status.idle":"2022-10-11T05:13:54.069722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X,Y = proc_images(0,90000)\ndf = pd.DataFrame()\ndf[\"images\"]=X\ndf[\"labels\"]=Y\nX2=df[\"images\"]\nY2=df[\"labels\"]\nX2=np.array(X2)\nimgs0=[]\nimgs1=[]\nimgs0 = X2[Y2==0] # (0 = no IDC, 1 = IDC)\nimgs1 = X2[Y2==1] ","metadata":{"_cell_guid":"3bf67ef8-5613-4862-bc46-0106d1880981","_uuid":"2b8fd5414423f1e7ff7da620d8672bb496a9ef57","execution":{"iopub.status.busy":"2022-10-11T05:13:54.070730Z","iopub.status.idle":"2022-10-11T05:13:54.071325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def describeData(a,b):\n    print('Total number of images: {}'.format(len(a)))\n    print('Number of IDC(-) Images: {}'.format(np.sum(b==0)))\n    print('Number of IDC(+) Images: {}'.format(np.sum(b==1)))\n    print('Percentage of positive images: {:.2f}%'.format(100*np.mean(b)))\n    print('Image shape (Width, Height, Channels): {}'.format(a[0].shape))\ndescribeData(X2,Y2)","metadata":{"_cell_guid":"b3c1681f-7576-4b3d-ad49-7832e3bcf209","_uuid":"5660e633007abaeda0a4698b8bfacf55d9552ab4","execution":{"iopub.status.busy":"2022-10-11T05:13:54.072207Z","iopub.status.idle":"2022-10-11T05:13:54.072682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict_characters = {0: 'IDC(-)', 1: 'IDC(+)'}\nprint(df.head(10))\nprint(\"\")\nprint(dict_characters)","metadata":{"_cell_guid":"0c3b967b-674c-4efa-b59e-56772166ef41","_uuid":"9eed051f46211121a7add96c9cf86165340a7e28","execution":{"iopub.status.busy":"2022-10-11T05:13:54.073426Z","iopub.status.idle":"2022-10-11T05:13:54.073939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotOne(a,b):\n    \"\"\"\n    Plot one numpy array\n    \"\"\"\n    plt.subplot(1,2,1)\n    plt.title('IDC (-)')\n    plt.imshow(a[0])\n    plt.subplot(1,2,2)\n    plt.title('IDC (+)')\n    plt.imshow(b[0])\nplotOne(imgs0, imgs1) ","metadata":{"_cell_guid":"d72d8a7d-7234-4a68-92f9-8f3578e08e36","_uuid":"3836924a638d95d90d85a02829bd85933f3c495f","execution":{"iopub.status.busy":"2022-10-11T05:13:54.074810Z","iopub.status.idle":"2022-10-11T05:13:54.075303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotTwo(a,b): \n    \"\"\"\n    Plot a bunch of numpy arrays sorted by label\n    \"\"\"\n    for row in range(3):\n        plt.figure(figsize=(20, 10))\n        for col in range(3):\n            plt.subplot(1,8,col+1)\n            plt.title('IDC (-)')\n            plt.imshow(a[0+row+col])\n            plt.axis('off')       \n            plt.subplot(1,8,col+4)\n            plt.title('IDC (+)')\n            plt.imshow(b[0+row+col])\n            plt.axis('off')\nplotTwo(imgs0, imgs1) ","metadata":{"_cell_guid":"389ea274-9f97-45e6-a99f-d3362412e721","_uuid":"c83c02425f516da672e7957f0cd42ecc72dce981","execution":{"iopub.status.busy":"2022-10-11T05:13:54.076196Z","iopub.status.idle":"2022-10-11T05:13:54.076653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotHistogram(a):\n    \"\"\"\n    Plot histogram of RGB Pixel Intensities\n    \"\"\"\n    plt.figure(figsize=(10,5))\n    plt.subplot(1,2,1)\n    plt.imshow(a)\n    plt.axis('off')\n    plt.title('IDC(+)' if Y[1] else 'IDC(-)')\n    histo = plt.subplot(1,2,2)\n    histo.set_ylabel('Count')\n    histo.set_xlabel('Pixel Intensity')\n    n_bins = 30\n    plt.hist(a[:,:,0].flatten(), bins= n_bins, lw = 0, color='r', alpha=0.5);\n    plt.hist(a[:,:,1].flatten(), bins= n_bins, lw = 0, color='g', alpha=0.5);\n    plt.hist(a[:,:,2].flatten(), bins= n_bins, lw = 0, color='b', alpha=0.5);\nplotHistogram(X2[100])","metadata":{"_cell_guid":"c5d01476-b570-4fb4-8ebb-1af69f3e215e","_uuid":"23ca1626461e4749493064070986a075f8317539","execution":{"iopub.status.busy":"2022-10-11T05:13:54.077438Z","iopub.status.idle":"2022-10-11T05:13:54.077881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=np.array(X)\nX=X/255.0\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n\n# REduction of the Sample Size for easing the Debugging process\nX_train = X_train[0:300000] \nY_train = Y_train[0:300000]\nX_test = X_test[0:300000] \nY_test = Y_test[0:300000]\n\nprint(\"Training Data Shape:\", X_train.shape)\nprint(\"Testing Data Shape:\", X_test.shape)","metadata":{"_cell_guid":"9f9e4c80-a8e0-47ac-957b-22231b1e9fca","_uuid":"ae82d3f7ec59d7d112a8dd9ed1b8121a4792a1b0","execution":{"iopub.status.busy":"2022-10-11T05:13:54.078888Z","iopub.status.idle":"2022-10-11T05:13:54.079489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotHistogram(X_train[100])","metadata":{"_cell_guid":"b07de5e9-53dd-49e5-9da3-778bc9eb9b17","_uuid":"5d808c28fb0f9aaa0364d8b62d11fc1f2810c2c8","execution":{"iopub.status.busy":"2022-10-11T05:13:54.080332Z","iopub.status.idle":"2022-10-11T05:13:54.080828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nY_trainHot = to_categorical(Y_train, num_classes = 2)\nY_testHot = to_categorical(Y_test, num_classes = 2)","metadata":{"_cell_guid":"a23e5463-5d12-43c8-8a3a-eb7dcfecdf6b","_uuid":"447f1371f137cf51962a0f32171d44a3080a694c","execution":{"iopub.status.busy":"2022-10-11T05:13:54.081648Z","iopub.status.idle":"2022-10-11T05:13:54.082226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lab = df['labels']\ndist = lab.value_counts()\nsns.countplot(lab)\nprint(dict_characters)","metadata":{"_cell_guid":"ab055bcf-2a2c-4645-b043-45d28ddcc782","_uuid":"1c05f8d5a5ada31b3741944ac02d480c2b39619f","execution":{"iopub.status.busy":"2022-10-11T05:13:54.082958Z","iopub.status.idle":"2022-10-11T05:13:54.083538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Deal with imbalanced class sizes below\n# Make Data 1D for compatability upsampling methods\nX_trainShape = X_train.shape[1]*X_train.shape[2]*X_train.shape[3]\nX_testShape = X_test.shape[1]*X_test.shape[2]*X_test.shape[3]\nX_trainFlat = X_train.reshape(X_train.shape[0], X_trainShape)\nX_testFlat = X_test.reshape(X_test.shape[0], X_testShape)\n\n\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\n\nros = RandomUnderSampler(ratio='auto')\nX_trainRos, Y_trainRos = ros.fit_sample(X_trainFlat, Y_train)\nX_testRos, Y_testRos = ros.fit_sample(X_testFlat, Y_test)\n\n# Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nY_trainRosHot = to_categorical(Y_trainRos, num_classes = 2)\nY_testRosHot = to_categorical(Y_testRos, num_classes = 2)\n\n\nfor i in range(len(X_trainRos)):\n    height, width, channels = 50,50,3\n    X_trainRosReshaped = X_trainRos.reshape(len(X_trainRos),height,width,channels)\n\nfor i in range(len(X_testRos)):\n    height, width, channels = 50,50,3\n    X_testRosReshaped = X_testRos.reshape(len(X_testRos),height,width,channels)\n\n\ndfRos = pd.DataFrame()\ndfRos[\"labels\"]=Y_trainRos\nlabRos = dfRos['labels']\ndistRos = lab.value_counts()\nsns.countplot(labRos)\nprint(dict_characters)","metadata":{"_cell_guid":"06cb3ea4-371a-4971-9449-dc726f06e16b","_uuid":"5d3087f0dfe874a591449b9d5f27da138f42f0c6","execution":{"iopub.status.busy":"2022-10-11T05:13:54.084438Z","iopub.status.idle":"2022-10-11T05:13:54.084898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Step 4: The Helper Functions are defined for the Classification Task to performed flawlessly*","metadata":{"_cell_guid":"11ec5cdf-44ad-4bf6-8975-4fa4682d5e2a","_uuid":"9265cdcdeb26c3169db18392ce1603885129a130"}},{"cell_type":"code","source":"from sklearn.utils import class_weight\nclass_weight = class_weight.compute_class_weight('balanced', np.unique(Y_train), Y_train)\nprint(\"Old Class Weights: \",class_weight)\nfrom sklearn.utils import class_weight\nclass_weight2 = class_weight.compute_class_weight('balanced', np.unique(Y_trainRos), Y_trainRos)\nprint(\"New Class Weights: \",class_weight2)","metadata":{"_cell_guid":"5a0e446b-a55a-4933-b4a7-198da1669545","_uuid":"ec338837016d3d5222e98a10331b1b2de457db34","execution":{"iopub.status.busy":"2022-10-11T05:13:54.085652Z","iopub.status.idle":"2022-10-11T05:13:54.086229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass MetricsCheckpoint(Callback):\n    \"\"\"Callback that saves metrics after each epoch\"\"\"\n    def __init__(self, savepath):\n        super(MetricsCheckpoint, self).__init__()\n        self.savepath = savepath\n        self.history = {}\n    def on_epoch_end(self, epoch, logs=None):\n        for k, v in logs.items():\n            self.history.setdefault(k, []).append(v)\n        np.save(self.savepath, self.history)\n\ndef plotKerasLearningCurve():\n    plt.figure(figsize=(10,5))\n    metrics = np.load('logs.npy')[()]\n    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n        l = np.array(metrics[k])\n        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n        y = l[x]\n        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n    plt.legend(loc=4)\n    plt.axis([0, None, None, None]);\n    plt.grid()\n    plt.xlabel('Number of epochs')\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize = (5,5))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\ndef plot_learning_curve(history):\n    plt.figure(figsize=(8,8))\n    plt.subplot(1,2,1)\n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.savefig('./accuracy_curve.png')\n    #plt.clf()\n    # summarize history for loss\n    plt.subplot(1,2,2)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.savefig('./loss_curve.png')","metadata":{"_cell_guid":"137bc037-a8a4-4dac-aecd-62d6efc6c127","_uuid":"4a883a6aaddd3261a630af0f12ed7e542da3eb3f","execution":{"iopub.status.busy":"2022-10-11T05:13:54.087070Z","iopub.status.idle":"2022-10-11T05:13:54.087606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Step 5: Evaluation of the Classification Models that will do the magic*","metadata":{"_cell_guid":"0fe72b01-0848-4ac9-b4b8-a2d212cfcc2d","_uuid":"4524ae34f83914f75a2da05afba664cf7f0ea505"}},{"cell_type":"code","source":"def runKerasCNNAugment(a,b,c,d,e,f):\n    \"\"\"\n  \n    \"\"\"\n    batch_size = 128\n    num_classes = 2\n    epochs = 8\n#     img_rows, img_cols = a.shape[1],a.shape[2]\n    img_rows,img_cols=50,50\n    input_shape = (img_rows, img_cols, 3)\n    model = Sequential()\n    model.add(Conv2D(32, kernel_size=(3, 3),\n                     activation='relu',\n                     input_shape=input_shape,strides=e))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(num_classes, activation='softmax'))\n    model.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer=keras.optimizers.Adadelta(),\n                  metrics=['accuracy'])\n    datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=True)  # randomly flip images\n    history = model.fit_generator(datagen.flow(a,b, batch_size=32),\n                        steps_per_epoch=len(a) / 32, epochs=epochs,class_weight=f, validation_data = [c, d],callbacks = [MetricsCheckpoint('logs')])\n    score = model.evaluate(c,d, verbose=0)\n    print('\\nKeras CNN #1C - accuracy:', score[1],'\\n')\n    y_pred = model.predict(c)\n    map_characters = {0: 'IDC(-)', 1: 'IDC(+)'}\n    print('\\n', sklearn.metrics.classification_report(np.where(d > 0)[1], np.argmax(y_pred, axis=1), target_names=list(map_characters.values())), sep='')    \n    Y_pred_classes = np.argmax(y_pred,axis=1) \n    Y_true = np.argmax(d,axis=1) \n    plotKerasLearningCurve()\n    plt.show()  \n    plot_learning_curve(history)\n    plt.show()\n    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n    plot_confusion_matrix(confusion_mtx, classes = list(dict_characters.values())) \n    plt.show()\nrunKerasCNNAugment(X_trainRosReshaped, Y_trainRosHot, X_testRosReshaped, Y_testRosHot,2,class_weight2)","metadata":{"_cell_guid":"47acf66e-5542-4f73-908c-11f76ed8becf","_uuid":"6d7e57d88e5578aea8b0b8f397d2a689e9c74de0","execution":{"iopub.status.busy":"2022-10-11T05:13:54.088447Z","iopub.status.idle":"2022-10-11T05:13:54.089067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer_outputs = [layer.output for layer in classifier.layers[:12]] # Extracts the outputs of the top 12 layers\nactivation_model = models.Model(inputs=model.input, outputs=layer_outputs) # Creates a model that will return these outputs, given the model input","metadata":{"execution":{"iopub.status.busy":"2022-10-11T05:13:54.089961Z","iopub.status.idle":"2022-10-11T05:13:54.090458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_tensor = image.img_to_array(imgage_name)\nimg_tensor = np.expand_dims(img_tensor, axis=0)\nimg_tensor /= 255.\n","metadata":{"execution":{"iopub.status.busy":"2022-10-11T05:13:54.091317Z","iopub.status.idle":"2022-10-11T05:13:54.091797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"activations = activation_model.predict(img_tensor) ","metadata":{"execution":{"iopub.status.busy":"2022-10-11T05:13:54.092507Z","iopub.status.idle":"2022-10-11T05:13:54.093054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"first_layer_activation = activations[0]\nprint(first_layer_activation.shape)","metadata":{"execution":{"iopub.status.busy":"2022-10-11T05:13:54.093847Z","iopub.status.idle":"2022-10-11T05:13:54.094396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.matshow(first_layer_activation[0, :, :, 4], cmap='viridis')","metadata":{"execution":{"iopub.status.busy":"2022-10-11T05:13:54.095193Z","iopub.status.idle":"2022-10-11T05:13:54.095725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer_names = []\nfor layer in classifier.layers[:12]:\n    layer_names.append(layer.name)]\n    \nimages_per_row = 16\n​\nfor layer_name, layer_activation in zip(layer_names, activations): # Displays the feature maps\n    n_features = layer_activation.shape[-1] # Number of features in the feature map\n    size = layer_activation.shape[1] #The feature map has shape (1, size, size, n_features).\n    n_cols = n_features // images_per_row # Tiles the activation channels in this matrix\n    display_grid = np.zeros((size * n_cols, images_per_row * size))\n    for col in range(n_cols): # Tiles each filter into a big horizontal grid\n        for row in range(images_per_row):\n            channel_image = layer_activation[0,\n                                             :, :,\n                                             col * images_per_row + row]\n            channel_image -= channel_image.mean() # Post-processes the feature to make it visually palatable\n            channel_image /= channel_image.std()\n            channel_image *= 64\n            channel_image += 128\n            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n            display_grid[col * size : (col + 1) * size, # Displays the grid\n                         row * size : (row + 1) * size] = channel_image\n    scale = 1. / size\n    plt.figure(figsize=(scale * display_grid.shape[1],\n                        scale * display_grid.shape[0]))\n    plt.title(layer_name)\n    plt.grid(False)\n    plt.imshow(display_grid, aspect='auto', cmap='viridis')","metadata":{"execution":{"iopub.status.busy":"2022-10-11T05:13:54.096539Z","iopub.status.idle":"2022-10-11T05:13:54.097062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"runKerasCNNAugment(X_train, Y_trainHot, X_test, Y_testHot,2,class_weight)","metadata":{"_cell_guid":"97db66e5-0fc8-4e1d-bfc0-179c3391f08f","_uuid":"9854e5bb4554a4bea7d59a37ec6d4a24ce141fc0","execution":{"iopub.status.busy":"2022-10-11T05:13:54.097803Z","iopub.status.idle":"2022-10-11T05:13:54.098303Z"},"trusted":true},"execution_count":null,"outputs":[]}]}